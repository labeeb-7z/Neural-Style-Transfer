{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08582447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-01 14:01:44.657935: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-01 14:01:44.657964: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7934f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9843f",
   "metadata": {},
   "source": [
    "mnist data consists of 70000 images, each of 28x28 pixels\n",
    "\n",
    "X_train -> 60000 x 28 x 28\n",
    "\n",
    "Y_train -> 60000 x 1\n",
    "\n",
    "X_test -> 10000 x 28 x 28\n",
    "\n",
    "Y_test -> 10000 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab313c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example : 34232 ------> label : 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#X_train -> 60000 x 28 x 28\n",
    "\n",
    "#visualizing the data\n",
    "index = 34232\n",
    "plt.imshow(X_train[index],cmap = 'gray')\n",
    "print(f\"example : {index} ------> label : {Y_train[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c654197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping and standardizing the data\n",
    "X = (X_train.reshape(X_train.shape[0],-1).T)/255\n",
    "Ytemp = Y_train.reshape(Y_train.shape[0],-1).T\n",
    "\n",
    "'''\n",
    "X = 784 x 60000\n",
    "Y = 1 x 60000 \n",
    "'''\n",
    "X_dev = (X_test.reshape(X_test.shape[0],-1).T)/255\n",
    "Y_devtemp = Y_test.reshape(Y_test.shape[0],-1).T\n",
    "'''\n",
    "X_dev = 784 x 10000\n",
    "Y_dev = 1 x 10000\n",
    "'''\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "Y=np.zeros((10,Ytemp.shape[1]))\n",
    "for i in range(Ytemp.shape[1]):\n",
    "    Y[Ytemp[0,i],i]=1\n",
    "\n",
    "Y_dev=np.zeros((10,Y_devtemp.shape[1]))\n",
    "for i in range(Y_devtemp.shape[1]):\n",
    "    Y_dev[Y_devtemp[0,i],i]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb92dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    for l in range(1, L):\n",
    "        parameters['W'+str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b'+str(l)] = np.zeros((layer_dims[l],1))\n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02eb573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(A,W,b,func):\n",
    "    Z = np.dot(W,A) + b\n",
    "    linear_cache = (A,W,b)\n",
    "    activation_cache = (Z)\n",
    "    \n",
    "    cache = (linear_cache,activation_cache)\n",
    "    \n",
    "    if func==\"Lrelu\" :\n",
    "        A = np.where(Z>0,Z,0.01*Z)\n",
    "        \n",
    "        \n",
    "    elif func==\"sigmoid\" :\n",
    "        A = 1/(1+np.exp(-Z))\n",
    "    \n",
    "    elif func==\"softmax\" :\n",
    "        A = np.exp(Z)/np.sum(np.exp(Z),axis=0)\n",
    "    \n",
    "    return A,cache\n",
    "\n",
    "\n",
    "\n",
    "def forward_propagation(X,parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(1,L) :\n",
    "        A,cache = get_activation(A,parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],\"Lrelu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    #print(A)\n",
    "    Y_hat,cache = get_activation(A,parameters[\"W\"+str(L)],parameters[\"b\"+str(L)],\"softmax\")\n",
    "    caches.append(cache)\n",
    "    #print(Y_hat)\n",
    "    return Y_hat,caches\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b94ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y_hat,Y,m) : \n",
    "    cost = (-1/m)*np.sum((Y*np.log(Y_hat)) + ((1-Y)*np.log((1-Y_hat))))\n",
    "                   \n",
    "    #cost = -(1/m)*np.sum((Y*np.log(AL)))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c846e61",
   "metadata": {},
   "source": [
    "dA of layer L -> gives us dW, db of Lth layer and dA of L-1 layer\n",
    "\n",
    "the we use dA of layer L-1 to get dW, db of layer L-1 and dA of layer L-2\n",
    "\n",
    "and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18cf3e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_backward(Y_hat,dA,cache,func) :\n",
    "    linear_cache, activation_cache = cache\n",
    "    A_prev, W, b = linear_cache\n",
    "    Z = activation_cache\n",
    "    \n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    if func == \"Lrelu\" :\n",
    "        #derivative of activation wrt to Z\n",
    "        temp = np.where(Z>0,1,0.01)\n",
    "        dZ = dA*temp\n",
    "    elif func == \"sigmoid\" :\n",
    "        sig = 1/(1+np.exp(-Z))\n",
    "        dZ = Y_hat - Y\n",
    "        \n",
    "    elif func == \"softmax\" :\n",
    "        soft = np.exp(Z)/np.sum(np.exp(Z))\n",
    "        dZ = Y_hat - Y\n",
    "    \n",
    "    dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "\n",
    "def backward_propagation(Y_hat,Y,caches) :\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    Y = Y.reshape(Y_hat.shape)\n",
    "    \n",
    "    \n",
    "    #compute derivative of predicted output wrt cost (dJ/dY_hat)\n",
    "    #dY_hat = dA of layer L\n",
    "    #dY_hat = - (np.divide(Y, Y_hat) - np.divide(1 - Y, 1 - Y_hat))\n",
    "    \n",
    "    \n",
    "    #computing dW,db, of layer L and dA of layer L-1\n",
    "    \n",
    "#     dA_prev,dW,db = get_activation_backward(Y_hat,dY_hat,caches[L-1],\"softmax\")\n",
    "    \n",
    "#     grads[\"dA\"+str(L-1)],grads[\"dW\"+str(L)],grads[\"db\"+str(L)] = dA_prev,dW,db\n",
    "\n",
    "    last_layer_cache = caches[L-1]\n",
    "    linear_cache, activation_cache = last_layer_cache\n",
    "    A_prev, W, b = linear_cache\n",
    "    Z = activation_cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dZ = Y_hat - Y\n",
    "    grads[\"dA\"+str(L-1)] = np.dot(W.T,dZ)\n",
    "    grads[\"dW\"+str(L)]   = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    grads[\"db\"+str(L)]   = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    \n",
    "    dA_prev = grads[\"dA\"+str(L-1)]\n",
    "    \n",
    "    #loop from L-2 to 0\n",
    "    for l in reversed(range(L-1)) :\n",
    "        \n",
    "        current_layer_cache = caches[l]\n",
    "        dA_prev,dw,db = get_activation_backward(Y_hat,dA_prev,current_layer_cache,\"Lrelu\")\n",
    "        \n",
    "        grads[\"dA\"+str(l)],grads[\"dW\"+str(l+1)],grads[\"db\"+str(l+1)] = dA_prev,dw,db\n",
    "        \n",
    "        \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8231e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(params,grads,learning_rate):\n",
    "    L = len(params)//2\n",
    "    parameters = params.copy()\n",
    "    for l in range(L) :\n",
    "        parameters[\"W\"+str(l+1)] = parameters[\"W\"+str(l+1)] - (learning_rate * grads[\"dW\"+str(l+1)])\n",
    "        parameters[\"b\"+str(l+1)] = parameters[\"b\"+str(l+1)] - (learning_rate * grads[\"db\"+str(l+1)])\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40668080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(Y_hat):\n",
    "    return np.argmax(Y_hat,0)\n",
    "\n",
    "def get_accuracy(predictions,Y):\n",
    "    predictions = predictions.reshape(1,predictions.shape[0])\n",
    "    #print(predictions.shape)\n",
    "    ans = 0\n",
    "    for i in range(Y.shape[1]) :\n",
    "        predict = predictions[0,i]\n",
    "        if Y[predict,i]==1 :\n",
    "            ans+=1\n",
    "    print(ans)\n",
    "    return str((ans/Y.shape[1])*100) + '%'\n",
    "\n",
    "def predict_L_layer(X,parameters):\n",
    "    AL,caches=forward_propagation(X,parameters)\n",
    "    prediction=np.argmax(AL,axis=0)\n",
    "    prediction.reshape(1,prediction.shape[0])\n",
    "    ans = 0\n",
    "    for i in range(10000) :\n",
    "        if prediction[0,i]==Y_dev[0,i] : \n",
    "            ans+=1\n",
    "    print(ans)\n",
    "    #return prediction.reshape(1,prediction.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9c20aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, learning_rate = 0.01, num_iterations = 3000, print_cost=False):\n",
    "    costs = []\n",
    "    parameters = initialize_params(layers_dims)\n",
    "    \n",
    "    #print(parameters)\n",
    "    for i in range(0, num_iterations):\n",
    "        Y_hat, caches = forward_propagation(X,parameters)\n",
    "        \n",
    "        \n",
    "        cost = compute_cost(Y_hat,Y,Y.shape[1])\n",
    "        \n",
    "        grads = backward_propagation(Y_hat,Y,caches)\n",
    "        \n",
    "        parameters = update_params(parameters,grads,learning_rate)\n",
    "        \n",
    "        \n",
    "        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "            #print(get_predictions(Y_hat).shape)\n",
    "            #print(Y.shape)\n",
    "            print(\"accuracy : \",get_accuracy(get_predictions(Y_hat),Y))\n",
    "        if i % 100 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    return parameters,costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb63f019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 3.251201142421806\n",
      "5296\n",
      "accuracy :  8.826666666666666%\n",
      "Cost after iteration 100: 1.8066448148433034\n",
      "44307\n",
      "accuracy :  73.845%\n",
      "Cost after iteration 200: 0.9212949503149214\n",
      "51371\n",
      "accuracy :  85.61833333333333%\n",
      "Cost after iteration 300: 0.7159495582372121\n",
      "53128\n",
      "accuracy :  88.54666666666667%\n",
      "Cost after iteration 400: 0.6280953950200298\n",
      "53811\n",
      "accuracy :  89.685%\n",
      "Cost after iteration 500: 0.5792253823918825\n",
      "54198\n",
      "accuracy :  90.33%\n",
      "Cost after iteration 600: 0.5464372225120203\n",
      "54466\n",
      "accuracy :  90.77666666666667%\n",
      "Cost after iteration 700: 0.5216901900874703\n",
      "54705\n",
      "accuracy :  91.175%\n",
      "Cost after iteration 800: 0.5015999077150896\n",
      "54917\n",
      "accuracy :  91.52833333333334%\n",
      "Cost after iteration 900: 0.48442551123313815\n",
      "55094\n",
      "accuracy :  91.82333333333334%\n",
      "Cost after iteration 1000: 0.4690068545840386\n",
      "55247\n",
      "accuracy :  92.07833333333333%\n",
      "Cost after iteration 1100: 0.4548337269521723\n",
      "55408\n",
      "accuracy :  92.34666666666666%\n",
      "Cost after iteration 1200: 0.4418713283188889\n",
      "55544\n",
      "accuracy :  92.57333333333332%\n",
      "Cost after iteration 1300: 0.4298441062096175\n",
      "55654\n",
      "accuracy :  92.75666666666666%\n",
      "Cost after iteration 1400: 0.4185399863370257\n",
      "55763\n",
      "accuracy :  92.93833333333333%\n",
      "Cost after iteration 1500: 0.40783765514118697\n",
      "55878\n",
      "accuracy :  93.13%\n",
      "Cost after iteration 1600: 0.3976270609192684\n",
      "55997\n",
      "accuracy :  93.32833333333333%\n",
      "Cost after iteration 1700: 0.38783624265123584\n",
      "56095\n",
      "accuracy :  93.49166666666666%\n",
      "Cost after iteration 1800: 0.37849245186177805\n",
      "56206\n",
      "accuracy :  93.67666666666666%\n",
      "Cost after iteration 1900: 0.36950143398510094\n",
      "56313\n",
      "accuracy :  93.855%\n",
      "Cost after iteration 2000: 0.36078209042839565\n",
      "56418\n",
      "accuracy :  94.03%\n",
      "Cost after iteration 2100: 0.3523774315426393\n",
      "56519\n",
      "accuracy :  94.19833333333332%\n",
      "Cost after iteration 2200: 0.3442792747083826\n",
      "56599\n",
      "accuracy :  94.33166666666666%\n",
      "Cost after iteration 2300: 0.33642689450275653\n",
      "56690\n",
      "accuracy :  94.48333333333333%\n",
      "Cost after iteration 2400: 0.32885283398043774\n",
      "56775\n",
      "accuracy :  94.625%\n",
      "Cost after iteration 2500: 0.3215535707230795\n",
      "56844\n",
      "accuracy :  94.74000000000001%\n",
      "Cost after iteration 2600: 0.3145444180252386\n",
      "56922\n",
      "accuracy :  94.87%\n",
      "Cost after iteration 2700: 0.30786237446401\n",
      "56982\n",
      "accuracy :  94.97%\n",
      "Cost after iteration 2800: 0.30147291341084587\n",
      "57060\n",
      "accuracy :  95.1%\n",
      "Cost after iteration 2900: 0.29534234617782984\n",
      "57135\n",
      "accuracy :  95.22500000000001%\n",
      "Cost after iteration 2999: 0.2895037658116387\n",
      "57195\n",
      "accuracy :  95.325%\n"
     ]
    }
   ],
   "source": [
    "parameters, costs = model(X,Y,[784,56,10],0.1,3000,True)\n",
    "\n",
    "#predictions_test_L=predict_L_layer(X_dev,parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db5279fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000)\n",
      "9508\n",
      "accuracy :  95.08%\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "predictions,cache = forward_propagation(X_dev,parameters)\n",
    "print(predictions.shape)\n",
    "\n",
    "print(\"accuracy : \",get_accuracy(get_predictions(predictions),Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40f9f0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Unpaired image-to-image translation with CycleGANs

The goal of a CycleGAN is simple, learn a mapping between some dataset, X, and another dataset, Y. For example, X could be a dataset of horse images and Y a dataset of zebra images.

![](https://i.imgur.com/N3yns39.jpg)

**The beauty of CycleGAN is that X and Y do not have to be paired. This means that we can give CycleGAN any images for X and any images for Y, even if each image in Y is not the direct mapping of the related image in X.**


### CycleGAN has two Generator networks
- Generator A: Learns a mapping G:X ->Y, where X is an image from the source domain A and Y is an image from the target domain B. It takes an image from the source domain A, and converts it into an image that is similar to an image from the target domain B. Basically, the aim of the network is to learn a mapping so that G(X) is similar to Y.
- Generator B: Learns a mapping F:Y->X, and then takes an image Y from the target domain B, and converts it into an image X that is similar to an image from the source domain A. Similarly, the aim of the network is to learn another mapping, so that F(G(X) is similar to X.


### CycleGAN has two Discriminator networks
- Discriminator A: The Discriminator A is to Discriminate between the images generated by the Generator network A, which are represented as G(X), and the real images from the source domain A, which are represented as X.
- Discriminator B: The Discriminator B is to Discriminate between the images generated by the Generator network B, which are represented as F(Y), and the real images from the source domain B, which are represented as Y.

![](https://i.imgur.com/Ks2GJ5Y.png)

**Formally, the objective for the mapping function G: X → Y and its discriminator Dy is written as:**
![](https://i.imgur.com/QAkjgXg.png)

Simply put, this objective measures how close to 1 the discriminator outputs for real images, log Dy(y), and how close to 0 the discriminator outputs for fake images, log(1-Dy(G(x))).

Alone, this is not enough to guarantee proper results. All this can guarantee is that G will produce images similar to real Y images, not that ŷ will be the appropriate mapping of x.

The brilliant tactic the authors implement here is called cycle consistency. Cycle consistency states that if G translates x into ŷ, F should be able to translate ŷ back into x — and vice versa.

![](https://i.imgur.com/47tdZzu.png)

Adding an identity loss generally helps preserve color and tint in translated images, especially for photo to image generations.

![](https://i.imgur.com/bTNFAam.png)



## Our Results
![](https://i.imgur.com/9LfsbkA.png)

![](https://i.imgur.com/5mIOXjA.png)

![](https://i.imgur.com/CXkbOw8.png)

![](https://i.imgur.com/pGe5cFQ.png)

![](https://i.imgur.com/XBbC5qi.png)

![](https://i.imgur.com/sEc3Gqs.png)

